# coding=utf-8
"""æ–°é—»æŠ¥å‘Šç”Ÿæˆæ¨¡å—"""

import os
import json
import tempfile
from pathlib import Path
from string import Template
from typing import List, Dict, Optional, Any, Tuple

from src.models.news import News, WordGroupStatistic
from src.utils.file import clean_title, html_escape
from src.utils.time import format_time_filename, format_date_folder

TEMPLATES_DIR = Path(__file__).resolve().parent.parent / "templates"
EMAIL_TEMPLATE_PATH = TEMPLATES_DIR / "email_report_template.html"
EMAIL_HERO_TAGLINE = "æ±‡é›† 11+ å¹³å°çƒ­ç‚¹ï¼Œå®æ—¶æ´å¯Ÿå…³é”®è¯ç»„åˆä¸æ–°å¢åŠ¨å‘ã€‚"
MODE_METADATA = {
    "daily": {
        "label": "å½“æ—¥æ±‡æ€»",
        "description": "èšç„¦å½“æ—¥è·¨å¹³å°å…³é”®è¯çƒ­åº¦ä¸èµ°åŠ¿"
    },
    "current": {
        "label": "å½“å‰æ¦œå•",
        "description": "é«˜é¢‘ç›‘æ§å½“å‰æ¦œå•å¹¶åŠæ—¶é¢„è­¦æ³¢åŠ¨"
    },
    "incremental": {
        "label": "å¢é‡ç›‘æ§",
        "description": "ä»…æ¨é€æ–°å¢çƒ­ç‚¹ï¼Œè¾…åŠ©å®æ—¶å†³ç­–"
    }
}


class NewsReporter:
    """æ–°é—»æŠ¥å‘Šç”Ÿæˆå™¨

    è´Ÿè´£ï¼š
    - å‡†å¤‡æŠ¥å‘Šæ•°æ®
    - æ ¼å¼åŒ–æ ‡é¢˜
    - ç”Ÿæˆå„ç§æ ¼å¼çš„æŠ¥å‘Šï¼ˆHTMLã€æ–‡æœ¬ç­‰ï¼‰
    """

    def __init__(self, rank_threshold: int = 10):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            rank_threshold: æ’åé˜ˆå€¼ï¼ˆç”¨äºé«˜äº®æ˜¾ç¤ºï¼‰
        """
        self.rank_threshold = rank_threshold
        self._email_template_cache: Optional[str] = None

    def prepare_report_data(
        self,
        stats: List[WordGroupStatistic],
        failed_ids: Optional[List[str]] = None,
        new_news_list: Optional[List[News]] = None,
        mode: str = "daily"
    ) -> Dict:
        """å‡†å¤‡æŠ¥å‘Šæ•°æ®

        Args:
            stats: è¯ç»„ç»Ÿè®¡åˆ—è¡¨
            failed_ids: å¤±è´¥çš„å¹³å°IDåˆ—è¡¨
            new_news_list: æ–°å¢æ–°é—»åˆ—è¡¨
            mode: æ¨¡å¼ (daily/current/incremental)

        Returns:
            Dict: æŠ¥å‘Šæ•°æ®å­—å…¸
        """
        # åœ¨å¢é‡æ¨¡å¼ä¸‹éšè—æ–°å¢æ–°é—»åŒºåŸŸ
        hide_new_section = mode == "incremental"

        # å¤„ç†æ–°å¢æ–°é—»
        processed_new_titles = []
        if not hide_new_section and new_news_list:
            # æŒ‰å¹³å°åˆ†ç»„
            new_by_platform = {}
            for news in new_news_list:
                platform_name = news.platform_name
                if platform_name not in new_by_platform:
                    new_by_platform[platform_name] = []
                new_by_platform[platform_name].append(news)

            for platform_name, news_list in new_by_platform.items():
                source_titles = []
                for news in news_list:
                    processed_title = {
                        "title": news.title,
                        "platform": news.platform,  # å¹³å°ID
                        "source_name": news.platform_name,
                        "time_display": "",
                        "count": 1,
                        "ranks": [news.rank],
                        "rank_threshold": self.rank_threshold,
                        "url": news.url,
                        "mobile_url": news.mobile_url or "",
                        "is_new": True,
                    }
                    source_titles.append(processed_title)

                if source_titles:
                    processed_new_titles.append({
                        "source_id": news.platform,
                        "source_name": platform_name,
                        "titles": source_titles,
                    })

        # å¤„ç†ç»Ÿè®¡æ•°æ®
        processed_stats = []
        for stat in stats:
            if stat.count <= 0:
                continue

            processed_titles = []
            for news in stat.news_list:
                # ä»extraä¸­è·å–ä¿¡æ¯
                extra = news.extra
                processed_title = {
                    "title": news.title,
                    "platform": news.platform,  # å¹³å°ID
                    "source_name": news.platform_name,
                    "time_display": extra.get("time_display", ""),
                    "count": extra.get("count", 1),
                    "ranks": extra.get("all_ranks", [news.rank]),
                    "rank_threshold": self.rank_threshold,
                    "url": news.url,
                    "mobile_url": extra.get("mobileUrl", ""),
                    "is_new": extra.get("is_new", False),
                }
                processed_titles.append(processed_title)

            processed_stats.append({
                "word": stat.word,
                "count": stat.count,
                "percentage": stat.percentage,
                "titles": processed_titles,
            })

        return {
            "stats": processed_stats,
            "new_titles": processed_new_titles,
            "failed_ids": failed_ids or [],
            "total_new_count": sum(
                len(source["titles"]) for source in processed_new_titles
            ),
        }

    def format_rank_display(
        self,
        ranks: List[int],
        rank_threshold: int,
        format_type: str
    ) -> str:
        """ç»Ÿä¸€çš„æ’åæ ¼å¼åŒ–æ–¹æ³•

        Args:
            ranks: æ’ååˆ—è¡¨
            rank_threshold: æ’åé˜ˆå€¼
            format_type: æ ¼å¼ç±»å‹ (html/feishu/dingtalk/wework/telegram/ntfy)

        Returns:
            str: æ ¼å¼åŒ–åçš„æ’åæ˜¾ç¤º
        """
        if not ranks:
            return ""

        unique_ranks = sorted(set(ranks))
        min_rank = unique_ranks[0]
        max_rank = unique_ranks[-1]

        # æ ¹æ®å¹³å°é€‰æ‹©é«˜äº®æ ¼å¼
        if format_type == "html":
            highlight_start = "<font color='red'><strong>"
            highlight_end = "</strong></font>"
        elif format_type == "feishu":
            highlight_start = "<font color='red'>**"
            highlight_end = "**</font>"
        elif format_type in ["dingtalk", "wework"]:
            highlight_start = "**"
            highlight_end = "**"
        elif format_type == "telegram":
            highlight_start = "<b>"
            highlight_end = "</b>"
        else:
            highlight_start = "**"
            highlight_end = "**"

        # åˆ¤æ–­æ˜¯å¦é«˜äº®
        is_highlight = min_rank <= rank_threshold

        if min_rank == max_rank:
            rank_text = f"[{min_rank}]"
        else:
            rank_text = f"[{min_rank} - {max_rank}]"

        if is_highlight:
            return f"{highlight_start}{rank_text}{highlight_end}"
        else:
            return rank_text

    def format_title_for_platform(
        self,
        platform: str,
        title_data: Dict,
        show_source: bool = True
    ) -> str:
        """ç»Ÿä¸€çš„æ ‡é¢˜æ ¼å¼åŒ–æ–¹æ³•

        Args:
            platform: å¹³å°ç±»å‹ (feishu/dingtalk/wework/telegram/ntfy/html)
            title_data: æ ‡é¢˜æ•°æ®å­—å…¸
            show_source: æ˜¯å¦æ˜¾ç¤ºæ¥æºå¹³å°

        Returns:
            str: æ ¼å¼åŒ–åçš„æ ‡é¢˜
        """
        rank_display = self.format_rank_display(
            title_data["ranks"],
            title_data["rank_threshold"],
            platform
        )

        link_url = title_data["mobile_url"] or title_data["url"]
        cleaned_title = clean_title(title_data["title"])
        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if platform == "feishu":
            return self._format_feishu(
                cleaned_title, link_url, title_prefix, title_data, rank_display, show_source
            )
        elif platform == "dingtalk":
            return self._format_dingtalk(
                cleaned_title, link_url, title_prefix, title_data, rank_display, show_source
            )
        elif platform == "wework":
            return self._format_wework(
                cleaned_title, link_url, title_prefix, title_data, rank_display, show_source
            )
        elif platform == "telegram":
            return self._format_telegram(
                cleaned_title, link_url, title_prefix, title_data, rank_display, show_source
            )
        elif platform == "ntfy":
            return self._format_ntfy(
                cleaned_title, link_url, title_prefix, title_data, rank_display, show_source
            )
        elif platform == "html":
            return self._format_html(
                cleaned_title, link_url, title_data, rank_display
            )
        else:
            return cleaned_title

    def _format_feishu(
        self,
        title: str,
        link_url: str,
        prefix: str,
        data: Dict,
        rank_display: str,
        show_source: bool
    ) -> str:
        """é£ä¹¦æ ¼å¼"""
        if link_url:
            formatted_title = f"[{title}]({link_url})"
        else:
            formatted_title = title

        if show_source:
            result = f"<font color='grey'>[{data['source_name']}]</font> {prefix}{formatted_title}"
        else:
            result = f"{prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if data["time_display"]:
            result += f" <font color='grey'>- {data['time_display']}</font>"
        if data["count"] > 1:
            result += f" <font color='green'>({data['count']}æ¬¡)</font>"

        return result

    def _format_dingtalk(
        self,
        title: str,
        link_url: str,
        prefix: str,
        data: Dict,
        rank_display: str,
        show_source: bool
    ) -> str:
        """é’‰é’‰æ ¼å¼"""
        if link_url:
            formatted_title = f"[{title}]({link_url})"
        else:
            formatted_title = title

        if show_source:
            result = f"[{data['source_name']}] {prefix}{formatted_title}"
        else:
            result = f"{prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if data["time_display"]:
            result += f" - {data['time_display']}"
        if data["count"] > 1:
            result += f" ({data['count']}æ¬¡)"

        return result

    def _format_wework(
        self,
        title: str,
        link_url: str,
        prefix: str,
        data: Dict,
        rank_display: str,
        show_source: bool
    ) -> str:
        """ä¼ä¸šå¾®ä¿¡æ ¼å¼"""
        return self._format_dingtalk(title, link_url, prefix, data, rank_display, show_source)

    def _format_telegram(
        self,
        title: str,
        link_url: str,
        prefix: str,
        data: Dict,
        rank_display: str,
        show_source: bool
    ) -> str:
        """Telegramæ ¼å¼"""
        if link_url:
            formatted_title = f'<a href="{link_url}">{html_escape(title)}</a>'
        else:
            formatted_title = title

        if show_source:
            result = f"[{data['source_name']}] {prefix}{formatted_title}"
        else:
            result = f"{prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if data["time_display"]:
            result += f" <code>- {data['time_display']}</code>"
        if data["count"] > 1:
            result += f" <code>({data['count']}æ¬¡)</code>"

        return result

    def _format_ntfy(
        self,
        title: str,
        link_url: str,
        prefix: str,
        data: Dict,
        rank_display: str,
        show_source: bool
    ) -> str:
        """ntfyæ ¼å¼"""
        if link_url:
            formatted_title = f"[{title}]({link_url})"
        else:
            formatted_title = title

        if show_source:
            result = f"[{data['source_name']}] {prefix}{formatted_title}"
        else:
            result = f"{prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if data["time_display"]:
            result += f" `- {data['time_display']}`"
        if data["count"] > 1:
            result += f" `({data['count']}æ¬¡)`"

        return result

    def _format_html(
        self,
        title: str,
        link_url: str,
        data: Dict,
        rank_display: str
    ) -> str:
        """HTMLæ ¼å¼"""
        escaped_title = html_escape(title)
        escaped_source_name = html_escape(data["source_name"])

        if link_url:
            escaped_url = html_escape(link_url)
            formatted_title = f'[{escaped_source_name}] <a href="{escaped_url}" target="_blank" class="news-link">{escaped_title}</a>'
        else:
            formatted_title = f'[{escaped_source_name}] <span class="no-link">{escaped_title}</span>'

        if rank_display:
            formatted_title += f" {rank_display}"
        if data["time_display"]:
            escaped_time = html_escape(data["time_display"])
            formatted_title += f" <font color='grey'>- {escaped_time}</font>"
        if data["count"] > 1:
            formatted_title += f" <font color='green'>({data['count']}æ¬¡)</font>"

        if data.get("is_new"):
            formatted_title = f"<div class='new-title'>ğŸ†• {formatted_title}</div>"

        return formatted_title

    def get_output_path(self, output_type: str, filename: str) -> Path:
        """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Args:
            output_type: è¾“å‡ºç±»å‹ (html/txt)
            filename: æ–‡ä»¶å

        Returns:
            Path: æ–‡ä»¶è·¯å¾„
        """
        date_folder = format_date_folder()
        output_dir = Path("output") / date_folder / output_type
        output_dir.mkdir(parents=True, exist_ok=True)
        return output_dir / filename

    def generate_text_report(
        self,
        stats: List[WordGroupStatistic],
        total_titles: int,
        failed_ids: Optional[List[str]] = None,
        new_news_list: Optional[List[News]] = None,
        mode: str = "daily",
        is_daily_summary: bool = False
    ) -> Path:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š

        Args:
            stats: è¯ç»„ç»Ÿè®¡åˆ—è¡¨
            total_titles: æ€»æ ‡é¢˜æ•°
            failed_ids: å¤±è´¥çš„å¹³å°IDåˆ—è¡¨
            new_news_list: æ–°å¢æ–°é—»åˆ—è¡¨
            mode: æ¨¡å¼
            is_daily_summary: æ˜¯å¦ä¸ºå½“æ—¥æ±‡æ€»

        Returns:
            Path: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨å›ºå®šæ–‡ä»¶å,ä¾¿äºè¯»å–å’Œå¢é‡å¯¹æ¯”
        if is_daily_summary:
            if mode == "current":
                filename = "å½“å‰æ¦œå•æ±‡æ€».txt"
            elif mode == "incremental":
                filename = "å½“æ—¥å¢é‡.txt"
            else:
                filename = "å½“æ—¥æ±‡æ€».txt"
        else:
            filename = f"{format_time_filename()}.txt"

        file_path = self.get_output_path("txt", filename)

        report_data = self.prepare_report_data(stats, failed_ids, new_news_list, mode)

        # å¦‚æœæ˜¯ "å½“æ—¥æ±‡æ€».txt" ä¸”æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨è¿½åŠ åˆå¹¶æ¨¡å¼
        if filename == "å½“æ—¥æ±‡æ€».txt" and file_path.exists():
            print(f"â„¹ï¸  æ£€æµ‹åˆ°ç°æœ‰æ±‡æ€»æ–‡ä»¶ï¼Œä½¿ç”¨è¿½åŠ åˆå¹¶æ¨¡å¼")
            return self._generate_merged_text_report(file_path, report_data)

        content_lines = []

        # å†™å…¥è¯ç»„ç»Ÿè®¡
        for stat in report_data["stats"]:
            content_lines.append(f"{stat['word']} (å…±{stat['count']}æ¡)")
            content_lines.append("")

            for title_data in stat["titles"]:
                # ç®€å•çš„æ–‡æœ¬æ ¼å¼
                line = f"[{title_data['source_name']}] {title_data['title']}"
                if title_data["ranks"]:
                    min_rank = min(title_data["ranks"])
                    max_rank = max(title_data["ranks"])
                    if min_rank == max_rank:
                        line += f" [{min_rank}]"
                    else:
                        line += f" [{min_rank} - {max_rank}]"
                if title_data["time_display"]:
                    line += f" - {title_data['time_display']}"
                if title_data["count"] > 1:
                    line += f" ({title_data['count']}æ¬¡)"
                if title_data["url"]:
                    line += f" [URL:{title_data['url']}]"
                if title_data["mobile_url"]:
                    line += f" [MOBILE:{title_data['mobile_url']}]"

                content_lines.append(line)

            content_lines.append("")

        # å†™å…¥æ–°å¢æ–°é—»
        if report_data["new_titles"]:
            content_lines.append("==== æœ€æ–°æ‰¹æ¬¡æ–°å¢ ====")
            content_lines.append("")

            for source_data in report_data["new_titles"]:
                content_lines.append(f"{source_data['source_name']} (æ–°å¢{len(source_data['titles'])}æ¡)")
                content_lines.append("")

                for title_data in source_data["titles"]:
                    line = f"{title_data['title']}"
                    if title_data["ranks"]:
                        line += f" [{title_data['ranks'][0]}]"
                    if title_data["url"]:
                        line += f" [URL:{title_data['url']}]"
                    if title_data["mobile_url"]:
                        line += f" [MOBILE:{title_data['mobile_url']}]"

                    content_lines.append(line)

                content_lines.append("")

        # å†™å…¥å¤±è´¥ä¿¡æ¯
        if report_data["failed_ids"]:
            content_lines.append("==== ä»¥ä¸‹IDè¯·æ±‚å¤±è´¥ ====")
            content_lines.append(", ".join(report_data["failed_ids"]))

        # å†™å…¥æ–‡ä»¶
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(content_lines))

        return file_path

    def generate_json_report(
        self,
        stats: List[WordGroupStatistic],
        total_titles: int,
        failed_ids: Optional[List[str]] = None,
        new_news_list: Optional[List[News]] = None,
        mode: str = "daily",
        is_daily_summary: bool = False  # pylint: disable=unused-argument
    ) -> Path:
        """ç”Ÿæˆ JSON æŠ¥å‘Š(å…¨é‡è¦†å†™æ¨¡å¼)

        Args:
            stats: è¯ç»„ç»Ÿè®¡åˆ—è¡¨
            total_titles: æ€»æ ‡é¢˜æ•°
            failed_ids: å¤±è´¥çš„å¹³å°IDåˆ—è¡¨
            new_news_list: æ–°å¢æ–°é—»åˆ—è¡¨
            mode: æ¨¡å¼
            is_daily_summary: æ˜¯å¦ä¸ºå½“æ—¥æ±‡æ€»

        Returns:
            Path: JSON æ–‡ä»¶è·¯å¾„
        """
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = self.prepare_report_data(stats, failed_ids, new_news_list, mode)

        # æ„å»ºå®Œæ•´ JSON æ•°æ®
        json_data = self._build_full_json_data(
            report_data=report_data,
            total_titles=total_titles,
            mode=mode
        )

        # è·å–æ–‡ä»¶è·¯å¾„
        json_path = self.get_output_path("json", "news_summary.json")

        # åŸå­å†™å…¥
        self._atomic_write_json(json_path, json_data)

        return json_path

    def _build_full_json_data(
        self,
        report_data: Dict,
        total_titles: int,  # pylint: disable=unused-argument
        mode: str
    ) -> Dict[str, Any]:
        """æ„å»ºå®Œæ•´ JSON æ•°æ®(åŒ…å«æ‰€æœ‰åŒ¹é…æ–°é—»)

        Args:
            report_data: prepare_report_data() è¿”å›çš„æ•°æ®
            total_titles: æ€»æ–°é—»æ•°
            mode: è¿è¡Œæ¨¡å¼

        Returns:
            Dict: å®Œæ•´ JSON æ•°æ®ç»“æ„
        """
        from src.utils.time import get_beijing_time

        now = get_beijing_time()

        # è½¬æ¢è¯ç»„ç»Ÿè®¡æ•°æ®(åŒ…å«æ‰€æœ‰æ–°é—»,ä¸è¿‡æ»¤ is_new)
        stats_list = []
        total_count = 0

        for stat in report_data["stats"]:
            news_list = []
            for title_data in stat["titles"]:
                news_item = {
                    "title": title_data["title"],
                    "url": title_data["url"],
                    "mobile_url": title_data["mobile_url"],
                    "platform": title_data["platform"],
                    "platform_name": title_data["source_name"],
                    "rank": min(title_data["ranks"]) if title_data["ranks"] else 999,
                    "ranks": title_data["ranks"],
                    "occurrence_count": title_data["count"],
                    "time_display": title_data["time_display"],
                }
                news_list.append(news_item)

            if news_list:
                total_count += len(news_list)
                stats_list.append({
                    "word_group": stat["word"],
                    "count": len(news_list),
                    "percentage": stat["percentage"],
                    "news_list": news_list,
                })

        return {
            "metadata": {
                "date": now.strftime("%Y-%m-%d"),
                "mode": mode,
                "timestamp": now.isoformat(),
                "total_word_groups": len(stats_list),
                "total_news_count": total_count,
            },
            "stats": stats_list,
        }

    def _atomic_write_json(self, file_path: Path, data: Dict[str, Any]) -> None:
        """åŸå­å†™å…¥ JSON æ–‡ä»¶

        å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶,æˆåŠŸåå†é‡å‘½å,é˜²æ­¢å†™å…¥å¤±è´¥å¯¼è‡´æ•°æ®ä¸¢å¤±ã€‚

        Args:
            file_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            data: è¦å†™å…¥çš„æ•°æ®
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶(åœ¨åŒä¸€ç›®å½•ä¸‹,ç¡®ä¿åŸå­ rename)
        fd, temp_path = tempfile.mkstemp(
            dir=file_path.parent,
            prefix=".tmp_",
            suffix=".json"
        )

        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with os.fdopen(fd, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # åŸå­é‡å‘½å
            os.replace(temp_path, file_path)
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_path)
            except:
                pass
            raise e

    def _parse_existing_summary(self, file_path: Path) -> Dict[str, Any]:
        """è§£æç°æœ‰çš„æ±‡æ€»æ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Dict: è§£æåçš„æ•°æ®ç»“æ„
                {
                    "stats": {word_group: {title: title_data}},
                    "failed_ids": [...]
                }
        """
        existing_stats = {}
        failed_ids = []
        current_word_group = None
        in_failed_section = False

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()

                    if not line:
                        continue

                    # æ£€æµ‹å¤±è´¥IDåŒºåŸŸå¼€å§‹
                    if line.startswith("==== ä»¥ä¸‹IDè¯·æ±‚å¤±è´¥ ===="):
                        in_failed_section = True
                        current_word_group = None  # é€€å‡ºè¯ç»„åŒºåŸŸ
                        continue

                    # æ£€æµ‹æ–°å¢æ–°é—»åŒºåŸŸï¼ˆç»“æŸè¯ç»„ç»Ÿè®¡åŒºåŸŸï¼‰
                    if line.startswith("==== æœ€æ–°æ‰¹æ¬¡æ–°å¢ ===="):
                        current_word_group = None
                        in_failed_section = False
                        continue

                    # å¦‚æœåœ¨å¤±è´¥IDåŒºåŸŸï¼Œè§£æå¤±è´¥ID
                    if in_failed_section:
                        if ',' in line:
                            failed_ids = [id.strip() for id in line.split(',') if id.strip()]
                        continue

                    # æ£€æµ‹è¯ç»„æ ‡é¢˜è¡Œ: "è¯ç»„å (å…±Næ¡)"
                    if line.endswith('æ¡)') and ' (å…±' in line:
                        # æå–è¯ç»„å
                        current_word_group = line.split(' (å…±')[0]
                        if current_word_group not in existing_stats:
                            existing_stats[current_word_group] = {}
                        continue

                    # è§£ææ ‡é¢˜è¡Œ: "[å¹³å°å] æ ‡é¢˜ [æ’å] - æ—¶é—´ [URL:...] [MOBILE:...]"
                    if line.startswith('[') and '] ' in line and current_word_group:
                        try:
                            # æå–å¹³å°åç§°
                            platform_end = line.index('] ')
                            platform_name = line[1:platform_end]
                            rest = line[platform_end + 2:]

                            # æå– MOBILE URL
                            mobile_url = ""
                            if " [MOBILE:" in rest:
                                rest, mobile_part = rest.rsplit(" [MOBILE:", 1)
                                if mobile_part.endswith("]"):
                                    mobile_url = mobile_part[:-1]

                            # æå– URL
                            url = ""
                            if " [URL:" in rest:
                                rest, url_part = rest.rsplit(" [URL:", 1)
                                if url_part.endswith("]"):
                                    url = url_part[:-1]

                            # æå–æ¬¡æ•°ä¿¡æ¯ "(Næ¬¡)"
                            count = 1
                            if " (" in rest and "æ¬¡)" in rest:
                                rest, count_part = rest.rsplit(" (", 1)
                                if count_part.endswith("æ¬¡)"):
                                    count_str = count_part[:-2]
                                    if count_str.isdigit():
                                        count = int(count_str)

                            # æå–æ—¶é—´ä¿¡æ¯ "- æ—¶é—´"
                            time_display = ""
                            if " - " in rest:
                                title_rank_part, time_display = rest.rsplit(" - ", 1)
                                rest = title_rank_part

                            # æå–æ’å "[æ’å]" æˆ– "[min - max]"
                            ranks = []
                            if " [" in rest and "]" in rest:
                                title_part, rank_part = rest.rsplit(" [", 1)
                                if rank_part.endswith("]"):
                                    rank_str = rank_part[:-1]
                                    if " - " in rank_str:
                                        # èŒƒå›´æ’å
                                        min_rank, max_rank = rank_str.split(" - ")
                                        if min_rank.isdigit() and max_rank.isdigit():
                                            ranks = list(range(int(min_rank), int(max_rank) + 1))
                                    elif rank_str.isdigit():
                                        ranks = [int(rank_str)]
                                rest = title_part

                            title = rest.strip()

                            # å­˜å‚¨æ ‡é¢˜æ•°æ®
                            if title not in existing_stats[current_word_group]:
                                existing_stats[current_word_group][title] = {
                                    "platform_name": platform_name,
                                    "url": url,
                                    "mobile_url": mobile_url,
                                    "ranks": ranks,
                                    "count": count,
                                    "time_display": time_display,
                                }

                        except Exception as e:
                            print(f"âš ï¸  è§£ææ ‡é¢˜è¡Œå¤±è´¥: {line[:50]}... é”™è¯¯: {e}")
                            continue

        except Exception as e:
            print(f"âš ï¸  è¯»å–æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}")

        return {
            "stats": existing_stats,
            "failed_ids": failed_ids,
        }

    def _merge_report_data(
        self,
        existing_data: Dict[str, Any],
        new_report_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆå¹¶ç°æœ‰æ•°æ®å’Œæ–°æ•°æ®

        Args:
            existing_data: ä»æ–‡ä»¶è§£æçš„ç°æœ‰æ•°æ®
            new_report_data: æ–°çš„æŠ¥å‘Šæ•°æ® (prepare_report_data è¿”å›)

        Returns:
            Dict: åˆå¹¶åçš„æŠ¥å‘Šæ•°æ®
        """
        merged_stats = []
        existing_stats = existing_data.get("stats", {})

        # å¤„ç†æ¯ä¸ªæ–°çš„è¯ç»„ç»Ÿè®¡
        for new_stat in new_report_data["stats"]:
            word_group = new_stat["word"]
            existing_titles = existing_stats.get(word_group, {})

            merged_titles = []
            seen_titles = set()

            # 1. å…ˆå¤„ç†æ–°æ•°æ®ä¸­çš„æ ‡é¢˜
            for new_title_data in new_stat["titles"]:
                title = new_title_data["title"]
                seen_titles.add(title)

                if title in existing_titles:
                    # æ ‡é¢˜å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                    existing_title_data = existing_titles[title]

                    # åˆå¹¶æ’å
                    existing_ranks = existing_title_data.get("ranks", [])
                    new_ranks = new_title_data.get("ranks", [])
                    merged_ranks = sorted(set(existing_ranks + new_ranks))

                    # æ›´æ–°å‡ºç°æ¬¡æ•°
                    existing_count = existing_title_data.get("count", 1)
                    merged_count = existing_count + 1

                    # ä½¿ç”¨æ–°æ•°æ®çš„å…¶ä»–ä¿¡æ¯
                    merged_title = new_title_data.copy()
                    merged_title["ranks"] = merged_ranks
                    merged_title["count"] = merged_count

                    # å¦‚æœç°æœ‰æ•°æ®æœ‰æ—¶é—´ä¿¡æ¯ï¼Œä¿ç•™
                    if existing_title_data.get("time_display"):
                        merged_title["time_display"] = existing_title_data["time_display"]

                    merged_titles.append(merged_title)
                else:
                    # æ–°æ ‡é¢˜ï¼Œç›´æ¥æ·»åŠ 
                    merged_titles.append(new_title_data)

            # 2. æ·»åŠ ç°æœ‰æ•°æ®ä¸­æœªåœ¨æ–°æ•°æ®ä¸­å‡ºç°çš„æ ‡é¢˜ï¼ˆå†å²æ ‡é¢˜ï¼‰
            for existing_title, existing_title_data in existing_titles.items():
                if existing_title not in seen_titles:
                    # è½¬æ¢ä¸º report_data æ ¼å¼
                    historical_title = {
                        "title": existing_title,
                        "platform": "",  # å†å²æ•°æ®å¯èƒ½ç¼ºå°‘å¹³å°ID
                        "source_name": existing_title_data.get("platform_name", ""),
                        "time_display": existing_title_data.get("time_display", ""),
                        "count": existing_title_data.get("count", 1),
                        "ranks": existing_title_data.get("ranks", []),
                        "rank_threshold": self.rank_threshold,
                        "url": existing_title_data.get("url", ""),
                        "mobile_url": existing_title_data.get("mobile_url", ""),
                        "is_new": False,
                    }
                    merged_titles.append(historical_title)

            # æ„å»ºåˆå¹¶åçš„è¯ç»„ç»Ÿè®¡
            merged_stats.append({
                "word": word_group,
                "count": len(merged_titles),
                "percentage": 0,  # ç¨åé‡æ–°è®¡ç®—
                "titles": merged_titles,
            })

        # é‡æ–°è®¡ç®—ç™¾åˆ†æ¯”
        total_count = sum(stat["count"] for stat in merged_stats)
        if total_count > 0:
            for stat in merged_stats:
                stat["percentage"] = round(stat["count"] / total_count * 100, 2)

        # åˆå¹¶å¤±è´¥ID
        existing_failed_ids = set(existing_data.get("failed_ids", []))
        new_failed_ids = set(new_report_data.get("failed_ids", []))
        merged_failed_ids = list(existing_failed_ids | new_failed_ids)

        return {
            "stats": merged_stats,
            "new_titles": new_report_data.get("new_titles", []),
            "failed_ids": merged_failed_ids,
            "total_new_count": new_report_data.get("total_new_count", 0),
        }

    def _generate_merged_text_report(
        self,
        file_path: Path,
        new_report_data: Dict[str, Any]
    ) -> Path:
        """ç”Ÿæˆåˆå¹¶åçš„æ–‡æœ¬æŠ¥å‘Š

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            new_report_data: æ–°çš„æŠ¥å‘Šæ•°æ®

        Returns:
            Path: æ–‡ä»¶è·¯å¾„
        """
        # 1. è§£æç°æœ‰æ±‡æ€»æ–‡ä»¶
        existing_data = self._parse_existing_summary(file_path)

        # 2. åˆå¹¶æ•°æ®
        merged_data = self._merge_report_data(existing_data, new_report_data)

        # 3. ç”Ÿæˆå†…å®¹
        content_lines = []

        # å†™å…¥è¯ç»„ç»Ÿè®¡
        for stat in merged_data["stats"]:
            content_lines.append(f"{stat['word']} (å…±{stat['count']}æ¡)")
            content_lines.append("")

            for title_data in stat["titles"]:
                # ç®€å•çš„æ–‡æœ¬æ ¼å¼
                line = f"[{title_data['source_name']}] {title_data['title']}"
                if title_data["ranks"]:
                    min_rank = min(title_data["ranks"])
                    max_rank = max(title_data["ranks"])
                    if min_rank == max_rank:
                        line += f" [{min_rank}]"
                    else:
                        line += f" [{min_rank} - {max_rank}]"
                if title_data["time_display"]:
                    line += f" - {title_data['time_display']}"
                if title_data["count"] > 1:
                    line += f" ({title_data['count']}æ¬¡)"
                if title_data["url"]:
                    line += f" [URL:{title_data['url']}]"
                if title_data["mobile_url"]:
                    line += f" [MOBILE:{title_data['mobile_url']}]"

                content_lines.append(line)

            content_lines.append("")

        # å†™å…¥æ–°å¢æ–°é—»ï¼ˆå¦‚æœæœ‰ï¼‰
        if merged_data["new_titles"]:
            content_lines.append("==== æœ€æ–°æ‰¹æ¬¡æ–°å¢ ====")
            content_lines.append("")

            for source_data in merged_data["new_titles"]:
                content_lines.append(f"{source_data['source_name']} (æ–°å¢{len(source_data['titles'])}æ¡)")
                content_lines.append("")

                for title_data in source_data["titles"]:
                    line = f"{title_data['title']}"
                    if title_data["ranks"]:
                        line += f" [{title_data['ranks'][0]}]"
                    if title_data["url"]:
                        line += f" [URL:{title_data['url']}]"
                    if title_data["mobile_url"]:
                        line += f" [MOBILE:{title_data['mobile_url']}]"

                    content_lines.append(line)

                content_lines.append("")

        # å†™å…¥å¤±è´¥ä¿¡æ¯
        if merged_data["failed_ids"]:
            content_lines.append("==== ä»¥ä¸‹IDè¯·æ±‚å¤±è´¥ ====")
            content_lines.append(", ".join(merged_data["failed_ids"]))

        # å†™å…¥æ–‡ä»¶
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(content_lines))

        print(f"âœ“ æ±‡æ€»æ–‡ä»¶å·²æ›´æ–°: {file_path.name}")
        return file_path

    def generate_html_report(
        self,
        stats: List[WordGroupStatistic],
        total_titles: int,
        failed_ids: Optional[List[str]] = None,
        new_news_list: Optional[List[News]] = None,
        mode: str = "daily",
        is_daily_summary: bool = False
    ) -> Path:
        """ç”Ÿæˆé‚®ä»¶ä¸“ç”¨çš„ HTML æŠ¥å‘Šï¼ˆæœåŠ¡å™¨ç«¯æ¸²æŸ“ï¼Œæ—  JS ä¾èµ–ï¼‰

        Args:
            stats: è¯ç»„ç»Ÿè®¡åˆ—è¡¨
            total_titles: æ€»æ ‡é¢˜æ•°
            failed_ids: å¤±è´¥çš„å¹³å°IDåˆ—è¡¨
            new_news_list: æ–°å¢æ–°é—»åˆ—è¡¨
            mode: æ¨¡å¼
            is_daily_summary: æ˜¯å¦ä¸ºå½“æ—¥æ±‡æ€»

        Returns:
            Path: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨å›ºå®šæ–‡ä»¶å
        if is_daily_summary:
            if mode == "current":
                filename = "email_report_current.html"
            elif mode == "incremental":
                filename = "email_report_incremental.html"
            else:
                filename = "email_report_daily.html"
        else:
            filename = f"email_{format_time_filename()}.html"

        file_path = self.get_output_path("html", filename)

        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = self.prepare_report_data(stats, failed_ids, new_news_list, mode)

        # ç”Ÿæˆ HTML å†…å®¹
        html_content = self._build_email_html(report_data, total_titles, mode)

        # å†™å…¥æ–‡ä»¶
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        return file_path

    def _build_email_html(
        self,
        report_data: Dict,
        total_titles: int,
        mode: str
    ) -> str:
        """æ„å»ºé‚®ä»¶ä¸“ç”¨çš„ HTML å†…å®¹ï¼ˆæ¨¡æ¿æ¸²æŸ“ï¼‰"""
        template = self._get_email_template()

        mode_info = MODE_METADATA.get(mode, {
            "label": mode or "è‡ªå®šä¹‰æ¨¡å¼",
            "description": "è‡ªåŠ¨ç”Ÿæˆçƒ­ç‚¹æŠ¥å‘Š"
        })
        mode_label = mode_info["label"]
        mode_description = mode_info["description"]

        from src.utils.time import get_beijing_time

        now = get_beijing_time()
        date_str = now.strftime("%Y-%m-%d")
        timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

        news_sections = self._render_word_groups(report_data.get("stats", []))
        new_section = self._render_new_section(
            report_data.get("new_titles", []),
            report_data.get("total_new_count", 0)
        )
        failed_section = self._render_failed_section(report_data.get("failed_ids", []))

        substitutions = {
            "page_title": f"TrendRadar - {mode_label} æŠ¥å‘Š",
            "mode_label": mode_label,
            "hero_tagline": EMAIL_HERO_TAGLINE,
            "meta_date": date_str,
            "meta_keywords": str(len(report_data.get("stats", []))),
            "meta_news": str(total_titles),
            "meta_updated": timestamp,
            "mode_description": mode_description,
            "news_sections": news_sections,
            "new_section": new_section,
            "failed_section": failed_section,
        }

        return template.safe_substitute(substitutions)

    def _get_email_template(self) -> Template:
        """è¯»å–å¹¶ç¼“å­˜ HTML æ¨¡æ¿"""
        if self._email_template_cache is None:
            if not EMAIL_TEMPLATE_PATH.exists():
                raise FileNotFoundError(
                    f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {EMAIL_TEMPLATE_PATH}"
                )
            self._email_template_cache = EMAIL_TEMPLATE_PATH.read_text(
                encoding="utf-8"
            )
        return Template(self._email_template_cache)

    def _render_word_groups(self, stats: List[Dict[str, Any]]) -> str:
        """æ¸²æŸ“è¯ç»„ç»Ÿè®¡åŒºåŸŸï¼ˆé‚®ä»¶å®‰å…¨ç‰ˆï¼‰"""
        if not stats:
            return self._render_empty_state()

        sections: List[str] = []
        for stat in stats:
            titles = stat.get("titles", [])
            body_rows = []
            for idx, title_data in enumerate(titles):
                body_rows.append(self._render_news_item(title_data, is_first=idx == 0))

            if not body_rows:
                body_rows.append(self._render_placeholder_item("è¯¥è¯ç»„æš‚æ— å¯å±•ç¤ºçš„æ–°é—»ã€‚"))

            percentage = stat.get("percentage")
            if isinstance(percentage, (int, float)):
                percentage_text = f"{percentage:.1f}% è¦†ç›–"
            elif percentage is not None:
                percentage_text = f"{percentage}% è¦†ç›–"
            else:
                percentage_text = ""

            meta_text = f"å…± {stat.get('count', 0)} æ¡"
            if percentage_text:
                meta_text += f" Â· {percentage_text}"

            sections.append(self._wrap_card(
                title=html_escape(stat.get("word", "æœªå‘½åè¯ç»„")),
                meta_text=html_escape(meta_text),
                body_rows="".join(body_rows)
            ))

        return "".join(sections)

    def _render_news_item(self, title_data: Dict[str, Any], is_first: bool = False) -> str:
        """æ¸²æŸ“å•æ¡æ–°é—»ï¼ˆå†…è”æ ·å¼ï¼‰"""
        link_url = title_data.get("mobile_url") or title_data.get("url") or ""
        title_text = html_escape(title_data.get("title", "æœªå‘½åæ ‡é¢˜"))

        if link_url:
            link_html = (
                f'<a href="{html_escape(link_url)}" '
                f'style="color:#0f6bff; text-decoration:none;">{title_text}</a>'
            )
        else:
            link_html = f'<span style="color:#111111;">{title_text}</span>'

        new_badge = ""
        if title_data.get("is_new"):
            new_badge = (
                '<span style="display:inline-block; padding:2px 8px; border-radius:999px; '
                'background-color:#e7f7ec; color:#0a8f08; font-size:11px; '
                'font-weight:600; margin-right:6px;">NEW</span>'
            )

        meta_parts: List[str] = []
        source_name = title_data.get("source_name")
        if source_name:
            meta_parts.append(f'<span>[{html_escape(source_name)}]</span>')

        rank_label, highlight = self._build_rank_chip(title_data.get("ranks", []))
        if rank_label:
            rank_color = "#c62828" if highlight else "#0f6bff"
            rank_bg = "#fdecef" if highlight else "#e6efff"
            meta_parts.append(
                f'<span style="display:inline-block; padding:2px 10px; border-radius:999px; '
                f'background-color:{rank_bg}; color:{rank_color}; font-size:12px; '
                f'font-weight:600;">{html_escape(rank_label)}</span>'
            )

        time_display = title_data.get("time_display")
        if time_display:
            meta_parts.append(f'<span>{html_escape(time_display)}</span>')

        count = title_data.get("count", 0)
        if count and count > 1:
            meta_parts.append(f'<span>{count} æ¬¡å‡ºç°</span>')

        meta_block = ""
        if meta_parts:
            meta_block = (
                "<div style=\"font-size:13px; color:#6e6e73; margin-top:6px;\">"
                + " &middot; ".join(meta_parts)
                + "</div>"
            )

        border_style = "border-top:1px solid #f1f2f6;" if not is_first else "border-top:none;"

        return f"""
        <tr>
            <td style="padding:12px 24px; {border_style}">
                <div style="font-size:15px; color:#111111; line-height:1.5;">
                    {new_badge}{link_html}
                </div>
                {meta_block}
            </td>
        </tr>
        """

    def _build_rank_chip(self, ranks: List[Any]) -> Tuple[str, bool]:
        """å°†æ’ååˆ—è¡¨æ ¼å¼åŒ–ä¸ºå¾½ç« æ–‡æœ¬"""
        normalized: List[int] = []
        for rank in ranks or []:
            try:
                normalized.append(int(rank))
            except (TypeError, ValueError):
                continue

        if not normalized:
            return "", False

        unique_ranks = sorted(set(normalized))
        min_rank = unique_ranks[0]
        max_rank = unique_ranks[-1]

        if min_rank == max_rank:
            label = f"#{min_rank}"
        else:
            label = f"#{min_rank} - #{max_rank}"

        highlight = self.rank_threshold and min_rank <= self.rank_threshold
        return label, bool(highlight)

    def _render_new_section(
        self,
        new_titles: List[Dict[str, Any]],
        total_new_count: int
    ) -> str:
        """æ¸²æŸ“æ–°å¢æ–°é—»åŒºåŸŸ"""
        if not new_titles:
            return ""

        blocks: List[str] = []
        for source_data in new_titles:
            titles = source_data.get("titles", [])
            if not titles:
                continue

            body_rows = []
            for idx, title in enumerate(titles):
                body_rows.append(self._render_news_item(title, is_first=idx == 0))

            blocks.append(self._wrap_card(
                title=html_escape(source_data.get("source_name", "æœªå‘½åæ¥æº")),
                meta_text=html_escape(f"æ–°å¢ {len(titles)} æ¡"),
                body_rows="".join(body_rows)
            ))

        if not blocks:
            return ""

        header = """
        <tr>
            <td style="padding:28px 36px 8px 36px; font-size:18px; font-weight:600; color:#111111;">
                ğŸ“¢ æœ€æ–°æ‰¹æ¬¡æ–°å¢
            </td>
        </tr>
        """

        summary_line = ""
        if total_new_count:
            summary_line = f"""
            <tr>
                <td style="padding:0 36px 12px 36px; font-size:13px; color:#6e6e73;">
                    å…± {total_new_count} æ¡æ–°å¢
                </td>
            </tr>
            """

        return header + summary_line + "".join(blocks)

    def _render_failed_section(self, failed_ids: List[str]) -> str:
        """æ¸²æŸ“å¤±è´¥å¹³å°å‘Šè­¦"""
        if not failed_ids:
            return ""

        unique_failed = sorted({fid for fid in failed_ids if fid})
        if not unique_failed:
            return ""

        failed_text = ", ".join(unique_failed)
        return f"""
        <tr>
            <td style="padding:24px 36px 0 36px;">
                <table role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-radius:20px; background-color:#fff4f0; border:1px solid #ffd6cc;">
                    <tr>
                        <td style="padding:18px 20px; font-size:14px; color:#b3261e;">
                            <strong style="display:block; margin-bottom:6px;">âš ï¸ ä»¥ä¸‹å¹³å°è¯·æ±‚å¤±è´¥</strong>
                            <span style="color:#7a2e23;">{html_escape(failed_text)}</span>
                        </td>
                    </tr>
                </table>
            </td>
        </tr>
        """

    def _render_empty_state(self) -> str:
        """å½“æ²¡æœ‰ç»Ÿè®¡æ•°æ®æ—¶çš„å ä½å†…å®¹"""
        body_rows = self._render_placeholder_item("å½“å‰æ²¡æœ‰å¯å±•ç¤ºçš„çƒ­ç‚¹è¯ç»„ï¼Œè¯·ç¨åå†è¯•ã€‚")
        return self._wrap_card(
            title="æš‚æ— æ•°æ®",
            meta_text="ç­‰å¾…æ–°çš„æŠ“å–æ‰¹æ¬¡",
            body_rows=body_rows
        )

    def _wrap_card(self, title: str, meta_text: str, body_rows: str) -> str:
        """Apple Mail é£æ ¼çš„å¡ç‰‡å®¹å™¨"""
        return f"""
        <tr>
            <td style="padding:0 36px 16px 36px;">
                <table role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse:separate; border-spacing:0; border:1px solid #e3e7ee; border-radius:28px; background-color:#ffffff;">
                    <tr>
                        <td style="padding:20px 24px 10px 24px;">
                            <table role="presentation" width="100%" cellpadding="0" cellspacing="0">
                                <tr>
                                    <td style="font-size:18px; font-weight:600; color:#111111;">{title}</td>
                                    <td style="font-size:13px; color:#6e6e73; text-align:right;">{meta_text}</td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                    {body_rows}
                </table>
            </td>
        </tr>
        """

    def _render_placeholder_item(self, message: str) -> str:
        """æ— å†…å®¹æ—¶çš„å ä½è¡Œ"""
        return f"""
        <tr>
            <td style="padding:18px 24px;">
                <div style="font-size:14px; color:#6e6e73;">{html_escape(message)}</div>
            </td>
        </tr>
        """
